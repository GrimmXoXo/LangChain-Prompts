{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting env from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(openai_api_key=os.getenv('OPENAI_API_KEY'),temperature=0.6)#value from 0-1 if value is towards 1 then it will be creative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='What is the capital of UK'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "London is the capital of the United Kingdom.\n"
     ]
    }
   ],
   "source": [
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['Hos.getenv('HUGGINGFACE_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GM\\Desktop\\practice\\LangChain Krish Naik\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '0.19.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "llm_huggingface=HuggingFaceHub(repo_id=\"google/flan-t5-large\",model_kwargs={'temperature':0,'max_length':64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=llm_huggingface.predict('Tell me the Capital of India and pakistan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delhi\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i'm a sailor i'm a sailor i'm a sailor i'm a sailor i'm a sailor i'm a sailor i'\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_huggingface.predict('Write a good song for me')#LMAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Verse 1\n",
      "Holding on to hope, while the days go by\n",
      "Fighting all the pain, trying not to cry\n",
      "When I'm feeling low, I just have to try\n",
      "To keep my head up high, and never say die\n",
      "\n",
      "Chorus\n",
      "I'm gonna make it through, no matter what it takes\n",
      "I'm gonna keep on fighting, no more heartbreaks\n",
      "I'm gonna take control, of my destiny\n",
      "And I know I'll find a way, for me to be free\n",
      "\n",
      "Verse 2\n",
      "I'm gonna keep on searching, for a better way\n",
      "I'm gonna keep on trying, every single day\n",
      "I'm gonna take the risk, and take a stand\n",
      "To find the courage, to keep going on\n",
      "\n",
      "Chorus\n",
      "I'm gonna make it through, no matter what it takes\n",
      "I'm gonna keep on fighting, no more heartbreaks\n",
      "I'm gonna take control, of my destiny\n",
      "And I know I'll find a way, for me to be free\n",
      "\n",
      "Bridge\n",
      "No more tears, no more fear\n",
      "No more pain, I'm gonna be here\n",
      "I'm gonna take a chance, on a brighter day\n",
      "To find a way, to make it all okay\n",
      "\n",
      "Ch\n"
     ]
    }
   ],
   "source": [
    "print(llm.predict(\"Write a good song for me\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates And LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of  India'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate(input_variables=['country'],template=\"Tell me the capital of  {country}\")\n",
    "prompt_template.format(country='India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Moscow\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain=LLMChain(llm=llm,prompt=prompt_template)\n",
    "print(chain.run('Russia'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Multiple chains using Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template=PromptTemplate(input_variables=['country'],template=\"Please tell me the capital of the {country}\")\n",
    "capital_chain=LLMChain(llm=llm,prompt=capital_template)\n",
    "\n",
    "famous_template=PromptTemplate(input_variables=['capital'],template='Suggest me good places to visit in {capital}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_chain=LLMChain(llm=llm,prompt=famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" It is a bustling city full of culture, history, and great places to visit. Some of the must-visit places in New Delhi include:\\n\\n1. India Gate: This iconic monument is a memorial to the soldiers who died in WWI and the Afghan Wars. It is also a popular tourist spot for visitors to the city.\\n\\n2. Red Fort: This majestic fort was built by Mughal emperor Shah Jahan in 1648. It is a symbol of India's rich history and cultural heritage.\\n\\n3. Qutub Minar: This towering minaret is the tallest brick minaret in the world and a UNESCO World Heritage Site.\\n\\n4. Jama Masjid: This grand mosque is one of the largest in India and is a must-visit for anyone interested in Islamic architecture.\\n\\n5. Humayun's Tomb: This grand mausoleum was built by Mughal emperor Humayun in 1570 and is a UNESCO World Heritage Site.\\n\\n6. Jantar Mantar: This observatory was built in 1724 by Maharaja Jai Singh II and is a great place to learn about astronomy and mathematics.\\n\\n7. Lotus Temple: This Bahá'í House of\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain=SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "chain.run('India')#only gave the last chains answer but not the prev chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see the entire chain\n",
    "q1template=PromptTemplate(input_variables=['year'],template='In the year {year} what was the most rememberable event that took place?')\n",
    "q1chain=LLMChain(llm=llm,prompt=q1template,output_key='event')#whatever this chains output key is will be sent to the next chains input\n",
    "\n",
    "q2template=PromptTemplate(input_variables=['event'],template='How did {event} impacted the world? Tell that in 5 words.')\n",
    "q2chain=LLMChain(llm=llm,prompt=q2template,output_key='impact')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': '2000',\n",
       " 'event': \"\\n\\nThe most memorable event of 2000 was the U.S. presidential election between George W. Bush and Al Gore. The election was one of the closest in history, with the Supreme Court ultimately deciding the outcome in Bush's favor. The election sparked a national debate about the Electoral College and voting rights that continues to this day.\",\n",
       " 'impact': '\\n\\nImpacted world with divisive politics.'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain2=SequentialChain(chains=[q1chain,q2chain],input_variables=['year'],output_variables=['event','impact'])\n",
    "year=input('Type the year for which you want a summary of event')\n",
    "chain2({'year':year})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Models with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage\n",
    "\n",
    "chatllm=ChatOpenAI(openai_api_key=os.getenv(\"OPEN_API_KEY\"),temperature=0.6,model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"Artificial intelligence is like a comedian without a sense of humor. It\\'s all about the data, but where\\'s the punchline?\"\\n\\n2. \"AI is like the ultimate wingman, always analyzing your every move and giving you advice. But hey, at least it doesn\\'t steal your nachos!\"\\n\\n3. \"They say AI will take over the world, but have you seen their fashion sense? I don\\'t think we have to worry about robots becoming the next fashion icons anytime soon.\"\\n\\n4. \"AI is like a magic eight ball, except instead of predicting the future, it just recommends cat videos.\"\\n\\n5. \"AI is like that friend who always thinks they know better than you. It\\'s like, \\'Thanks for the advice, but I\\'ll stick to my own questionable life choices, thank you very much!\\'\"\\n\\n6. \"AI is like a personal assistant, but with a lot less judgment and a lot more emojis.\"\\n\\n7. \"AI is like a really smart toddler. It can do amazing things, but sometimes it just randomly blurts out nonsense.\"\\n\\n8. \"AI is like a detective, always searching for answers. But instead of solving crimes, it just wants to know what kind of pizza you like.\"\\n\\n9. \"AI is like a really advanced GPS system. It can guide you through life, but it still can\\'t help you find your car keys.\"\\n\\n10. \"AI is like that friend who always corrects your grammar. It\\'s like, \\'Okay, robot, thanks for making me feel dumb AND self-conscious!\\'\"')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm(\n",
    "[\n",
    "    SystemMessage(content='You are a Comedian AI Assistant'),\n",
    "    HumanMessage(content='Please provide some punchlines on AI')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt template + LLM +Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        return text.strip().split(',')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "template='You are a good assistant. When the user gives any input you should generate 5 synonyms in comma seperated format'\n",
    "human_template='{text}'\n",
    "chat_prompt=ChatPromptTemplate.from_messages([\n",
    "    ('system',template),\n",
    "    ('human',human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chat_prompt|chatllm|Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dignity', ' respect', ' prestige', ' integrity', ' reverence']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'text':'honor'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
